{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTment 14-15 statistics  708631 19917 100\n",
      "Training logloss: 0.587821, Test logloss 0.588461, Train AUC 0.625288, Test AUC 0.623188\n",
      "Training logloss: 0.587243, Test logloss 0.587903, Train AUC 0.625589, Test AUC 0.623934\n",
      "Training logloss: 0.587312, Test logloss 0.587964, Train AUC 0.625579, Test AUC 0.623671\n",
      "Training logloss: 0.587278, Test logloss 0.587905, Train AUC 0.625529, Test AUC 0.623991\n",
      "Training logloss: 0.587042, Test logloss 0.587761, Train AUC 0.625602, Test AUC 0.623390\n",
      "Training logloss: 0.587304, Test logloss 0.588013, Train AUC 0.625482, Test AUC 0.623055\n",
      "Training logloss: 0.588354, Test logloss 0.589133, Train AUC 0.625430, Test AUC 0.623219\n",
      "Training logloss: 0.587350, Test logloss 0.588058, Train AUC 0.625430, Test AUC 0.623258\n",
      "Training logloss: 0.587255, Test logloss 0.587841, Train AUC 0.625472, Test AUC 0.623877\n",
      "Training logloss: 0.587392, Test logloss 0.588092, Train AUC 0.625320, Test AUC 0.623116\n",
      "Training logloss: 0.587021, Test logloss 0.587737, Train AUC 0.625757, Test AUC 0.623414\n",
      "Training logloss: 0.587184, Test logloss 0.587828, Train AUC 0.625673, Test AUC 0.623841\n",
      "Training logloss: 0.588094, Test logloss 0.588848, Train AUC 0.625497, Test AUC 0.622974\n",
      "Training logloss: 0.587370, Test logloss 0.588007, Train AUC 0.625456, Test AUC 0.623408\n",
      "Training logloss: 0.587506, Test logloss 0.588242, Train AUC 0.625580, Test AUC 0.623496\n",
      "Training logloss: 0.587150, Test logloss 0.587906, Train AUC 0.625572, Test AUC 0.623068\n",
      "Training logloss: 0.588028, Test logloss 0.588748, Train AUC 0.625606, Test AUC 0.623464\n",
      "Training logloss: 0.587596, Test logloss 0.588180, Train AUC 0.625250, Test AUC 0.623785\n",
      "Training logloss: 0.587132, Test logloss 0.587806, Train AUC 0.625585, Test AUC 0.623501\n",
      "Training logloss: 0.587346, Test logloss 0.588034, Train AUC 0.625663, Test AUC 0.623456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global bias, user bias, skill bias [0.94067911] [ 0.084365    0.1043262   0.04228349 ...  0.12342143 -0.02476095\n",
      " -0.05938827] [-0.14479674  0.30829739  0.0037907   0.21821146 -0.06260282  0.73445257\n",
      " -0.16892307 -0.34192753 -0.45799891 -0.14570562  0.05747    -0.34451525\n",
      "  0.19031965 -0.32213255  0.40354049  0.22607909  0.54623705  0.14799079\n",
      " -0.15596512  0.43674895  0.72146359 -0.02173024  0.50460287  0.33321189\n",
      "  0.48562827 -0.01937808  0.57075215 -0.0088415   0.00927341  0.49035149\n",
      "  0.05613335  0.07682943  0.27473148  0.02869041  0.26366058  0.25563425\n",
      "  0.58596588 -0.11448809  0.17307118  0.31554323  0.32334858 -0.01502579\n",
      "  0.37713977  0.18343488  0.13994514 -0.00262058 -0.03119312  0.53898854\n",
      "  0.12910285  0.36326292 -0.07421728  0.07983206 -0.55180195  0.61522062\n",
      "  0.44775033 -0.14010587 -0.06956748 -0.56778643 -0.0504572  -0.30270227\n",
      " -0.12227264 -0.22405292 -0.49042903 -0.30892132 -0.1743254  -0.018755\n",
      " -0.47260435  0.43328505 -0.14130595  0.1271485   0.3844092   0.25795481\n",
      "  0.63412556  0.3733394  -0.04508743 -0.08706337 -0.12644959  0.19591964\n",
      " -0.08380615  0.3068449  -0.22183691 -0.49238807 -0.16022619  0.40908237\n",
      " -0.26209108 -0.05382345  0.06592202  0.54438661  0.62954818 -0.31608606\n",
      " -0.02224425  0.25740495 -0.23868018 -0.29179314  0.03101611 -0.12171058\n",
      "  0.03693354 -0.05523057 -0.64448256 -0.4305794 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from PreprocessAssistment import *\n",
    "\n",
    "from IRT import IRT\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "file_path = \"/home/lxu/Documents/StudentLearningProcess/2015_ASSISTment.pickle\"\n",
    "data = pd.read_pickle(file_path)\n",
    "print('ASSISTment 14-15 statistics ', data.shape[0],  len(np.unique(data['user_id'])), len(np.unique(data['skill_id'])))\n",
    "\n",
    "\n",
    "# prepare data\n",
    "datanp = data.iloc[:,0:-1].values\n",
    "hist = data.iloc[:,data.shape[1]-1].values\n",
    "trainnp, testnp, hist_train, hist_test = train_test_split(datanp, hist, test_size=0.2)\n",
    "#\n",
    "columnNames = list(data.head(0))\n",
    "train = pd.DataFrame(data=trainnp, columns=columnNames[0:-1])\n",
    "test = pd.DataFrame(data=testnp, columns=columnNames[0:-1])\n",
    "\n",
    "train['hist'] = hist_train\n",
    "test['hist'] = hist_test\n",
    "\n",
    "for i in range(data.shape[1]-1):\n",
    "    train.iloc[:,i] = train.iloc[:,i].astype(np.int)\n",
    "    test.iloc[:,i] = test.iloc[:,i].astype(np.int)\n",
    "\n",
    "def PlotLoss(model, model_name):\n",
    "    plt.plot(range(model.maxepoch), model.acc_train, marker='o', label='ACC: Train Data')\n",
    "    plt.plot(range(model.maxepoch), model.acc_test, marker='v', label='ACC: Test Data')\n",
    "    plt.plot(range(model.maxepoch), model.auc_train, marker='+', label='AUC: Train Data')\n",
    "    plt.plot(range(model.maxepoch), model.auc_test, marker='*', label='AUC: Test Data')\n",
    "    plt.title('The Truncated Assitment Dataset Learning Curve ' + model_name)\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "# baseline model: global + user  + skill\n",
    "name = 'baseline'\n",
    "model = IRT()\n",
    "model.set_params({ \"epsilon\": 1, \"_lambda\": 0.2, \"momentum\": 0.5, \"maxepoch\": 20, \"num_batches\": 300,\n",
    "                            \"batch_size\": 1000, 'user':False})\n",
    "model.fit(train, test, len(np.unique(data['user_id'])), len(np.unique(data['skill_id'])), 10) # IRT\n",
    "\n",
    "PlotLoss(model, name)\n",
    "\n",
    "print('global bias, user bias, skill bias', model.beta_global,model.beta_user, model.beta_skill)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of records: 708631.\n",
      "After dropping NaN rows, # of records: 708631.\n",
      "statistics  708631 19917 100\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708631, 4)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
